{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is based on Lab 5.4 Contextualized_Vectors with multiple adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the file\n",
    "file_path = 'translated_dataset_4.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Lithuanian sentences (dataset and CTranslate)\n",
    "lt_dataset_sentences = data.iloc[:, 2]\n",
    "lt_ctranslate_sentences = data.iloc[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/LaD/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading the model\n",
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating sentence vectors\n",
    "def generate_vectors(sentences):\n",
    "    \"\"\" Takes a list of sentences and generate vector representations for each of them.\n",
    "    sentence in a list using a pre-trained transformer model. Returns a NumPy array \n",
    "    containing the sentence vectors, where each row represents the vector of one sentence.\"\"\"\n",
    "    \n",
    "    vectors = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sent in sentences:\n",
    "            tokens = tokenizer(sent, return_tensors = \"pt\", truncation = True, max_length = 512, padding = True)\n",
    "            output = model(**tokens)\n",
    "            vector = output.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "            vectors.append(vector)\n",
    "            \n",
    "    return np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vectors for both datasets\n",
    "dataset_vectors = generate_vectors(lt_dataset_sentences)\n",
    "ctranslate_vectors = generate_vectors(lt_ctranslate_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Computing cosine similarity for corresponding pairs\n",
    "pair_similarities = []\n",
    "for i in range(523):\n",
    "    sim = cosine_similarity([dataset_vectors[i]], [ctranslate_vectors[i]])[0][0]\n",
    "    pair_similarities.append((i + 1, i + 1 + 523, sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset Sentence ID  CTranslate Sentence ID  Cosine Similarity\n",
      "0                    1                     524           1.000000\n",
      "1                    2                     525           1.000000\n",
      "2                    3                     526           0.997474\n",
      "3                    4                     527           1.000000\n",
      "4                    5                     528           0.998462\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame to store results\n",
    "similarity_df = pd.DataFrame(pair_similarities, columns = [\"Dataset Sentence ID\", \"CTranslate Sentence ID\", \"Cosine Similarity\"])\n",
    "print(similarity_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the results to a CSV file\n",
    "output_filename_csv = \"similarity_scores.csv\"\n",
    "output_file_path_csv = \"/Users/urtejakubauskaite/Desktop/Language as Data/Labs/Lab5/code/\" + output_filename_csv\n",
    "similarity_df.to_csv(output_file_path_csv, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaDKernel",
   "language": "python",
   "name": "ladkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
