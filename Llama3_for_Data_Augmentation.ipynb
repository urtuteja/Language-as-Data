{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3576606-f6ea-4a3e-b21b-5484932c1ecd",
   "metadata": {},
   "source": [
    "# Data Augmention using Generative LLM - Llama 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa848bce-082d-419b-a47d-147bf77424da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from collections import defaultdict as dd\n",
    "\n",
    "# Point to the server\n",
    "#client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"cltl\")\n",
    "\n",
    "client = OpenAI(base_url=\"http://130.37.53.128:9002/v1\", api_key=\"cltl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fff3396",
   "metadata": {},
   "source": [
    "## First Prompt\n",
    "\n",
    "The task involves asking the model to translate multiple Lithuanian sentences into English simultaneously. These sentences include minimal pairs of the verb eiti (to walk) with different verbal prefixes. The prompt consists of an instruction, input data, and an output indicator.\n",
    "\n",
    "The temperature was set to 0.2 to prioritize consistent and accurate responses over creative ones. However, this prompt proved ineffective for data augmentation, as LLaMA 3 failed to provide accurate translations and did not use the expected verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"Translate these Lithuanian sentences to English: \n",
    "# \"Jis iš tolo apėjo mano naujausią parodą, nes bijojo tenai sutikti savo priešą.\", \"Ji atėjo \n",
    "# į mano naujausią parodą saulei jau leidžiantis.\", \"Jie įėjo į mano naujausią parodą \n",
    "# jaukioje salėje.\", \"Jūs išėjote iš mano naujausios parodos į lauką.\", \"Tu pagaliau nuėjai \n",
    "# į mano naujausią parodą.\", \"Jis šiek tiek paėjo mano naujausios parodos link, bet tuomet \n",
    "# apsisuko atgal.\", \"Aš parėjau iš mano naujausios parodos namo ir pradėjau gaminti vakarienę.\", \n",
    "# \"Jis gretai perėjo per mano naujausią parodą, bet nerado nė vieno patinkančio darbo.\", \n",
    "# \"Vaikščiodamas mieste, jis netyčia priėjo mano naujausią parodą ir labai dėl to nustebo.\", \n",
    "# \"Mano naujausiai parodai suėjo metai, o ji vis dar yra populiariausia mieste.\", \n",
    "# \"Jis trumpam užėjo į mano parodą, bet prižadėjo greitai sugrįžti.\"\n",
    "# Your answer should be a list of list in Python. The first element of each list should \n",
    "# contain the English translation and the second element should contain the Lithuanian \n",
    "# sentence. Provide only the list and nothing else. For example:[[\"english translation\"], \n",
    "# [\"lithuanian sentence\"], ...].\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586010dc",
   "metadata": {},
   "source": [
    "## Second Prompt\n",
    "\n",
    "The second prompt asks the model to create sentences using Lithuanian prefixed verbs derived from eiti (to walk). The prompt includes an instruction, input data, and an output indicator.\n",
    "\n",
    "The temperature was set to 0.2 to ensure consistent and accurate responses, prioritizing precision over creativity. However, this prompt was not effective for data augmentation, as LLaMA 3 failed to provide accurate responses and did not use the verbs correctly.\n",
    "\n",
    "An alternative version of this prompt included several examples to guide the model, but the results remained unsatisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ''' Create Lithuanian sentences using these words (you can use inflection) and \n",
    "# then translate them to English: apeiti, ateiti, įeiti, išeiti, nueiti, paeiti, pareiti, \n",
    "# pereiti, praeiti, prieiti, sueiti, užeiti. The sentences should be 6-10 words long. Your \n",
    "# answer should be a list of list in Python. The first element of each list should contain the \n",
    "# English translation and the second element should contain the Lithuanian sentence. Provide \n",
    "# only the list and nothing else. For example: [[\"English translation\"], [\"Lithuanian \n",
    "# sentence], ...]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772ab09",
   "metadata": {},
   "source": [
    "## Third Prompt\n",
    "\n",
    "The third prompt asks the model to generate English sentences using specific verbs and then translate them into Lithuanian. The prompt includes an instruction, input data, and an output indicator.\n",
    "\n",
    "The temperature was set to 0.2 to prioritize consistency and accuracy over creativity. However, this prompt performed poorly. The Lithuanian sentences contained numerous errors, including gender and number disagreements as well as incorrect lexical choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"Generate 6-8 word long English sentences one of these verbs in each sentence: \n",
    "# bypass, come, enter, leave, reach, walk a bit, return, pass, approach, come together, stop by.\n",
    "# Then, translate the sentences to Lithuanian. Your answer should be a list of list in Python. \n",
    "# The first element of each list should contain the English sentence and the second element \n",
    "# should contain the Lithuanian translation. Provide only the list and nothing else. For example:\n",
    "# [[\"English sentence\"], [\"Lithuanian sentence\"], ...].\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d65b9",
   "metadata": {},
   "source": [
    "## Fourth Prompt\n",
    "\n",
    "The fourth prompt asks the model to generate random English sentences and subsequently translate them into Lithuanian. The prompt includes an instruction, input data, and an output indicator.\n",
    "\n",
    "The temperature was set to 0.2 to ensure consistent and accurate responses rather than creative ones. However, this prompt performed poorly. The Lithuanian sentences were riddled with errors, including gender and number disagreements as well as incorrect lexical choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"Generate 15 English sentences that are 10 word long. Then, translate the \n",
    "# sentences to Lithuanian. Your answer should be a list of list in Python. \n",
    "# The first element of each list should contain the English sentence and the second element \n",
    "# should contain the Lithuanian translation. Provide only the list and nothing else. For example:\n",
    "# [[\"English sentence\"], [\"Lithuanian sentence\"], ...].\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a6b63",
   "metadata": {},
   "source": [
    "## Fifth Prompt\n",
    "\n",
    "The fifth prompt instructs the model to translate a Lithuanian article into English, sentence by sentence. The prompt includes an instruction, input data, and an output indicator.\n",
    "\n",
    "The temperature was set to 0.2 to prioritize consistent and accurate responses over creative ones. Llama 3 generated two versions for each sentence, allowing me to select the better option. This prompt yielded the best results: the generated English sentences were accurate, clear, and grammatically correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "191d3f25-6c36-4f9e-9aad-b3a3baeee91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "DONE:\n",
      "['However, as he says, in any case it is usually related to human error.']\n",
      "\n",
      "\n",
      "['Anot jo, vis dėlto dažniausiai tai susiję su žmogiška ja klaida.']\n",
      "\n",
      "\n",
      "['However, as it is often related to human error.']\n",
      "\n",
      "\n",
      "['Anot jo, vis dėlto dažniausiai tai susiję su žmogiška klaida.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = '''Translate this sentence from Lithuanian to English. Your answer should be a list of list in Python. The first element of each list should contain the English \n",
    "translation and the second element should contain the Lithuanian sentence. Provide only the \n",
    "list and nothing else. For example:[[\"English translation\"], [\"Lithuanian sentence\"]].\n",
    "\n",
    "The sentence: Anot jo, vis dėlto dažniausiai tai susiję su žmogiškąja klaida. ''' \n",
    "\n",
    "mt_list = []\n",
    "\n",
    "import json\n",
    "\n",
    "while len(mt_list) < 3:\n",
    "    answer = query_LLM(client, prompt, temp = 0.2)\n",
    "\n",
    "    try:\n",
    "        a = json.loads(answer)\n",
    "\n",
    "        for item in a:\n",
    "            mt_list.append(item)\n",
    "    except:\n",
    "        print(\"Failed to parse: \", answer)\n",
    "        print(\"Trying again!\\n\\n\\n\")\n",
    "\n",
    "print(\"\\n\\n\\nDONE:\")\n",
    "for pair in mt_list:\n",
    "    print(pair)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752c226-fbef-4110-96dd-a5eefc4c3382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c5e1ec2-a17c-4950-ae0e-6c8bef1e3731",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d158d3-94ba-419c-b5a3-fe43cf92ac64",
   "metadata": {},
   "source": [
    "# Quality Estimation / \"Evaluation\" with BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8432c9-dd2f-4cb0-8df8-e22af0d23dbe",
   "metadata": {},
   "source": [
    "<center><img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhdPDCCJH2WVAuEWUvp-RWdQITk9L8dB2p62GVI9CzLHd_hC2cED4wovkTY07sSZmYHtiWcHbSUhPRzbg_2DYyHiq_9gElMN85ZwZAI2gPcuwQNleQATdqUlrd8klzjOLhvh-weaAWdqkA2/s1600/BLEU4.png\" alt=\"llama\" style=\"width:90%\"></a><br><a href=\"https://kv-emptypages.blogspot.com/2019/04/understanding-mt-quality-bleu-scores.html\">Taken from/Read more here</a></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8f5af-9517-4141-9cba-89c93a1a1dcc",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6c4a0-7f8c-42bc-8edc-7edc96cddb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28504467-e1aa-4112-a9fa-9745c3df484b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/lmc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5c2c008-1081-4d6b-b015-5b069aabb75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the',), ('teacher',), ('arrived',), ('late',), ('because',), ('of',), ('the',), ('traffic',), ('the', 'teacher'), ('teacher', 'arrived'), ('arrived', 'late'), ('late', 'because'), ('because', 'of'), ('of', 'the'), ('the', 'traffic'), ('the', 'teacher', 'arrived'), ('teacher', 'arrived', 'late'), ('arrived', 'late', 'because'), ('late', 'because', 'of'), ('because', 'of', 'the'), ('of', 'the', 'traffic'), ('the', 'teacher', 'arrived', 'late'), ('teacher', 'arrived', 'late', 'because'), ('arrived', 'late', 'because', 'of'), ('late', 'because', 'of', 'the'), ('because', 'of', 'the', 'traffic')]\n"
     ]
    }
   ],
   "source": [
    "source_sent = \"le professeur est arrivé en retard à cause de la circulation\"\n",
    "reference_transl = \"the teacher arrived late because of the traffic\"\n",
    "reference_transl_tok = nltk.word_tokenize(reference_transl)\n",
    "ngrams_reference = []\n",
    "for n in [1,2,3,4]:\n",
    "    ngrams_reference = ngrams_reference + list(ngrams(reference_transl_tok,n))\n",
    "\n",
    "print(ngrams_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89839c6d-acf3-4048-b3ae-471c3d3c592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'professor', 'was', 'delayed', 'due', 'to', 'the', 'congestion'], ['Congestion', 'was', 'responsible', 'for', 'the', 'teacher', 'being', 'late'], ['The', 'teacher', 'was', 'late', 'due', 'to', 'the', 'traffic'], ['The', 'professor', 'arrived', 'late', 'because', 'circulation'], ['The', 'teacher', 'arrived', 'late', 'because', 'of', 'the', 'traffic']]\n"
     ]
    }
   ],
   "source": [
    "transl_list = [\n",
    "    \"The professor was delayed due to the congestion\",\n",
    "    \"Congestion was responsible for the teacher being late\",\n",
    "    \"The teacher was late due to the traffic\",\n",
    "    \"The professor arrived late because circulation\",\n",
    "    \"The teacher arrived late because of the traffic\"\n",
    "]\n",
    "\n",
    "transl_list_tokenized = []\n",
    "for sent in transl_list:\n",
    "    transl_list_tokenized.append(nltk.word_tokenize(sent))\n",
    "\n",
    "print(transl_list_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c87278c-c738-4d4f-8c4e-29648aa06f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0832677820940877e-231 1.052691193011681e-277\n",
      "{('the',)}\n",
      "\n",
      "\n",
      "\n",
      "7.176381577237209e-155 1.2950316234712509e-185\n",
      "{('the', 'teacher'), ('teacher',), ('late',), ('the',)}\n",
      "\n",
      "\n",
      "\n",
      "7.711523862191631e-155 1.3328284280434942e-185\n",
      "{('the',), ('teacher',), ('late',), ('traffic',), ('the', 'traffic')}\n",
      "\n",
      "\n",
      "\n",
      "4.1382219658909647e-78 1.695647221393335e-93\n",
      "{('arrived', 'late'), ('arrived', 'late', 'because'), ('because',), ('late',), ('late', 'because'), ('arrived',)}\n",
      "\n",
      "\n",
      "\n",
      "0.8408964152537145 0.834236890454548\n",
      "{('teacher', 'arrived'), ('of', 'the', 'traffic'), ('late', 'because', 'of', 'the'), ('the',), ('late', 'because'), ('because', 'of'), ('arrived', 'late', 'because', 'of'), ('arrived', 'late'), ('teacher', 'arrived', 'late', 'because'), ('teacher', 'arrived', 'late'), ('because', 'of', 'the', 'traffic'), ('arrived',), ('late', 'because', 'of'), ('because', 'of', 'the'), ('late',), ('of', 'the'), ('because',), ('arrived', 'late', 'because'), ('teacher',), ('traffic',), ('the', 'traffic'), ('of',)}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "ngram_weights = (0.10, 0.30, 0.30, 0.30) # weights for 1-gram, 2-gram, 3-gram, 4-gram\n",
    "\n",
    "for translation in transl_list_tokenized:\n",
    "\n",
    "    # Fine the translation n-grams\n",
    "    # Not needed for the score, just to see the overlap\n",
    "    sent_ngrams = []\n",
    "    for n in [1,2,3,4]:\n",
    "        sent_ngrams = sent_ngrams + list(ngrams(translation,n))\n",
    "    \n",
    "    \n",
    "    bleu_score1 = sentence_bleu([reference_transl_tok], translation)  # This can be a list of references \n",
    "    bleu_score2 = sentence_bleu([reference_transl_tok], translation, weights=ngram_weights) # This can be a list of references \n",
    "\n",
    "    print(bleu_score1, bleu_score2)\n",
    "\n",
    "    #1-gram overlap\n",
    "    print(set(ngrams_reference) & set(sent_ngrams))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342171e5-87e5-4c68-8b4f-d7e77bb54e07",
   "metadata": {},
   "source": [
    "## Why is the last one not 1.0?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
